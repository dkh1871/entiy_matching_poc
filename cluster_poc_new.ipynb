{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abeb90dc-9ce4-46c0-9f6a-a910e5637e18",
   "metadata": {},
   "source": [
    "# Title: DSC680 Project 1: Entity Matching POC \n",
    "## Author: David Hatchett  \n",
    "## Created: 2025-01-10  \n",
    "\n",
    "## Description:  \n",
    "The code below is a project to test if we can take a list of messy data with human errors and some clean data, and use clustering to identify the correct records.\n",
    "This code is not fully realized and is put together so I can rerun the process as needed. There are many hard-coded values in the functions.\n",
    "However, the purpose is to create a POC and show that it could work with unlabeled data.\n",
    "\n",
    "The scrambled data is a list of 1,520 records generated from a list of 20 company names and addresses. You can see the code for the scrambling process\n",
    "in this repo. Only about 60% of the data was scrambled, and we then dropped another 20% to create something more like real-life data.\n",
    "\n",
    "\n",
    "The code works in the following manner:\n",
    "1. Ingest the file of scrambled data\n",
    "2. Do cleaning on the test fields\n",
    "3. Create a clean name and full address (street, city, zip, state in one field.\n",
    "4. Sort the data set by clean name (this was added for chunking records for clustering, which wasn't fully implemented)\n",
    "5. Split the validation data from the test data\n",
    "6. Cluster the data using HDBSCAN\n",
    "7. Evaluate the clustering\n",
    "8. Compare the clustering to the validation set\n",
    "\n",
    "Overall, this looks like a viable process, but it definitely needs some work to improve the underlying code. I consulted ChatGPT on the overall idea of this process; however, aside from some cleaning functions, the code was written by me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d864cdc-f518-4a46-8acf-69b7feb9e345",
   "metadata": {},
   "source": [
    "## Set up Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6cfb30-9bd8-457b-b5b3-88b9a7424c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "import re\n",
    "import unicodedata\n",
    "import jellyfish\n",
    "import matplotlib \n",
    "import Levenshtein as lev\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d3ca40-0359-443b-b14e-83fb5fc6b90a",
   "metadata": {},
   "source": [
    "# Set up varables needed for the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0157954d-85cb-46d6-81b1-2246af3144e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "STREET_MAP = {\n",
    "    \"STREET\": \"ST\",\n",
    "    \"AVENUE\": \"AVE\",\n",
    "    \"BOULEVARD\": \"BLVD\",\n",
    "    \"ROAD\": \"RD\",\n",
    "    \"DRIVE\": \"DR\",\n",
    "    \"LANE\": \"LN\",\n",
    "    \"COURT\": \"CT\",\n",
    "    \"PLACE\": \"PL\"\n",
    "}\n",
    "\n",
    "DIRECTION_MAP = {\n",
    "    \"NORTH\": \"N\",\n",
    "    \"SOUTH\": \"S\",\n",
    "    \"EAST\": \"E\",\n",
    "    \"WEST\": \"W\",\n",
    "    \"NORTHWEST\":\"NW\",\n",
    "    \"NORTHEAST\":\"NE\",\n",
    "    \"SOUTHEAST\":\"SE\",\n",
    "    \"SOUTHWEST\":\"SW\"\n",
    "}\n",
    "\n",
    "UNIT_MAP = {\n",
    "    \"APARTMENT\": \"APT\",\n",
    "    \"SUITE\": \"STE\",\n",
    "    \"UNIT\": \"UNIT\"\n",
    "}\n",
    "\n",
    "LEGAL_SUFFIXES = {\n",
    "    \" INCORPORATED\": \"\",\n",
    "    \" INC\": \"\",\n",
    "    \" LLC\": \"\",\n",
    "    \" L L C\": \"\",\n",
    "    \" LTD\": \"\",\n",
    "    \" LIMITED\": \"\",\n",
    "    \" CORP\": \"\",\n",
    "    \" CORPORATION\": \"\",\n",
    "    \" CO\": \"\",\n",
    "    \" COMPANY\": \"\"\n",
    "}\n",
    "\n",
    "STOPWORDS = {\n",
    "    \"THE\": \"\",\n",
    "    \"AND\": \"\",\n",
    "    \"OF\": \"\",\n",
    "    \"AT\": \"\",\n",
    "    \"FOR\": \"\"}\n",
    "\n",
    "\n",
    "US_STATES = {\n",
    "    'AA',\n",
    "    'AE',\n",
    "    'AK',\n",
    "    'AL',\n",
    "    'AP',\n",
    "    'AR',\n",
    "    'AS',\n",
    "    'AZ',\n",
    "    'CA',\n",
    "    'CO',\n",
    "    'CT',\n",
    "    'DC',\n",
    "    'DE',\n",
    "    'FL',\n",
    "    'FM',\n",
    "    'GA',\n",
    "    'GU',\n",
    "    'HI',\n",
    "    'IA',\n",
    "    'ID',\n",
    "    'IL',\n",
    "    'IN',\n",
    "    'KS',\n",
    "    'KY',\n",
    "    'LA',\n",
    "    'MA',\n",
    "    'MD',\n",
    "    'ME',\n",
    "    'MH',\n",
    "    'MI',\n",
    "    'MN',\n",
    "    'MO',\n",
    "    'MP',\n",
    "    'MS',\n",
    "    'MT',\n",
    "    'NC',\n",
    "    'ND',\n",
    "    'NE',\n",
    "    'NH',\n",
    "    'NJ',\n",
    "    'NM',\n",
    "    'NV',\n",
    "    'NY',\n",
    "    'OH',\n",
    "    'OK',\n",
    "    'OR',\n",
    "    'PA',\n",
    "    'PR',\n",
    "    'PW',\n",
    "    'RI',\n",
    "    'SC',\n",
    "    'SD',\n",
    "    'TN',\n",
    "    'TX',\n",
    "    'UT',\n",
    "    'VA',\n",
    "    'VI',\n",
    "    'VT',\n",
    "    'WA',\n",
    "    'WI',\n",
    "    'WV',\n",
    "    'WY',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdca7d9-4cbd-4b6d-b279-ae2b37bd4718",
   "metadata": {},
   "source": [
    "## Set up Needed Functions for the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "955f1fc6-0ff2-4eea-a257-4c8d87050453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text:str) -> str:\n",
    "    '''\n",
    "    This function will clean up the strings \n",
    "    passed into it and return a string. Cleaned up\n",
    "    ChatGPT Function.\n",
    "\n",
    "    It uppercases the text\n",
    "    removes any characters not alphabetical\n",
    "    removes any extra text.\n",
    "    '''\n",
    "    text = str(text).upper()\n",
    "    text = re.sub(r\"[^A-Z0-9\\s]\", \" \", text)\n",
    "    text = remove_extra_spaces(text)\n",
    "    return text\n",
    "\n",
    "def normalize_name(name:str) -> str:\n",
    "    '''\n",
    "    used to normalize a name. \n",
    "    Parts of this were pulled from ChatGPT.\n",
    "\n",
    "    uses unicodedata and Normalization Form Canonical Compatibility Decomposition(NFKD)\n",
    "    and then remove anything that isn't ASCII.\n",
    "    uppercase the data\n",
    " \n",
    "    '''\n",
    "    if not name:\n",
    "        return \"\"\n",
    "\n",
    "    name = str(name)\n",
    "\n",
    "    name = unicodedata.normalize(\"NFKD\", name)\n",
    "    name = name.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    name = name.upper()\n",
    "    name = re.sub(r\"[^A-Z0-9\\s]\", \" \", name)\n",
    "    name = remove_extra_spaces(name)\n",
    "    return name\n",
    "\n",
    "def replace_values(text, mapping) -> str:\n",
    "    '''\n",
    "    General purpose function to replace\n",
    "    whatever is passed in the mapping \n",
    "    variable in the string using regex.\n",
    "    '''\n",
    "    for k, v in mapping.items():\n",
    "        text = re.sub(rf'\\b{k}\\b', v, text)\n",
    "    return text\n",
    "\n",
    "def remove_extra_spaces(text:str) -> str:\n",
    "    '''\n",
    "    remove any instated of double spaces \n",
    "    from a string. came from Chatgtp.\n",
    "    '''\n",
    "    return re.sub(r'\\s+', ' ', text).strip()    \n",
    "\n",
    "def normalize_phone(p:str) -> str:\n",
    "    '''\n",
    "    subtutes any none numeric char\n",
    "    with '' \n",
    "    '''\n",
    "    p = str(p)\n",
    "    if pd.isna(p):\n",
    "        return \"\"\n",
    "    digits = re.sub(r\"\\D\", \"\", p)\n",
    "    return digits\n",
    "\n",
    "def get_area_code(phn_nbr:str)->str:\n",
    "    '''\n",
    "    strips the area code from the phone\n",
    "    '''\n",
    "    return phn_nbr[0:3] if len(phn_nbr) ==10 else \"\"\n",
    "\n",
    "def truncate_phone_number(phn_nbr:str)->str:\n",
    "    '''\n",
    "    truncate the phone number after we split the \n",
    "    area code\n",
    "    '''\n",
    "    return phn_nbr[-7:] if len(phn_nbr) >=7 else \"\"\n",
    "\n",
    "\n",
    "def check_if_value_exists(text:str,chck_list:list) -> bool:\n",
    "    '''\n",
    "    used to see if a value exist in a provided list\n",
    "    '''\n",
    "    for i in chck_list:\n",
    "        if text == i:\n",
    "            return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90f4e6-d66c-4899-ac61-49037c04c3c7",
   "metadata": {},
   "source": [
    "## Set up Clustering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25228f9a-94e2-4c66-94c5-3d7a154bef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_data(df:pd.DataFrame):\n",
    "    '''\n",
    "    This is an exsample of how to do the clustering by chucking the data. \n",
    "    Not fully implement but does work. Next steps would be to make this more generic.\n",
    "    outline for this came from ChatGtp however it was quite off and need a lot of \n",
    "    work to fix.\n",
    "    '''\n",
    "    \n",
    "    df['cluster_persistence'] = np.nan\n",
    "    df['cluster_id'] = -1\n",
    "    cluster_offset = 0\n",
    "\n",
    "    ## blocking the data by state - change this to block differntly.\n",
    "    ## starts the loop to process each block\n",
    "    for block, data in df.groupby('state'):\n",
    "        if len(data) < 2:\n",
    "            continue  \n",
    "    \n",
    "        idx = data.index\n",
    "    \n",
    "        #create vector embeddings\n",
    "        name_vect = TfidfVectorizer(lowercase=False, analyzer='char_wb', ngram_range=(3,5)).fit_transform(data['name_clean'])\n",
    "        addrss_vect = TfidfVectorizer(lowercase=False, analyzer='char_wb', ngram_range=(3,5)).fit_transform(data['address_full'])\n",
    "\n",
    "        ## use hstack to bring the data togher.\n",
    "        ## weight the name higher then address\n",
    "        ## this was suggested by Chatgtp\n",
    "        features = hstack([\n",
    "            name_vect * .8,\n",
    "            addrss_vect * .2,\n",
    "        ])\n",
    "    \n",
    "\n",
    "        ## clsuter the data I should set this up to \n",
    "        ## a pramter in the futher.\n",
    "        clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size = 5,\n",
    "            min_samples = 1,\n",
    "            metric=\"cosine\",\n",
    "            # cluster_selection_epsilon = .5\n",
    "        )\n",
    "\n",
    "        ## get the lables out of the data\n",
    "        labels = clusterer.fit_predict(features)\n",
    "        labels.astype(\"int64\")\n",
    "\n",
    "        ## create list used to update the dataframe\n",
    "        ## CLUSTER ID AND cluster_persistence_\n",
    "        test_list = []\n",
    "        for i in labels:\n",
    "            if i == -1:\n",
    "                test_list.append(np.nan)\n",
    "            else:\n",
    "                test_list.append(clusterer.cluster_persistence_[i])\n",
    "                \n",
    "        \n",
    "        labels = np.where(\n",
    "            labels != -1,\n",
    "            labels + cluster_offset,\n",
    "            -1\n",
    "        )\n",
    "\n",
    "        \n",
    "        ## udpate the dataframe\n",
    "        df.loc[idx, \"cluster_id\"] = labels\n",
    "        df.loc[idx, \"cluster_persistence\"] = test_list\n",
    "\n",
    "        ## update the offset so no clustes overide. in the next block.\n",
    "        if max(labels) > 0:\n",
    "            cluster_offset = max(labels) + 1\n",
    "\n",
    "\n",
    "def small_cluster(df:pd.DataFrame, mcs=2, ms=1, mtr='cosine'):\n",
    "    '''\n",
    "    this is the cluster used in this POC. set up so we can test differnt \n",
    "    parmeters for hdbscan. this is set up to handle about 20k records\n",
    "    however this depends on your memory.\n",
    "    '''\n",
    "\n",
    "    ## add columns to the dataframe\n",
    "    df['cluster_persistence'] = np.nan\n",
    "    df['cluster_id'] = -1\n",
    "\n",
    "    ## pull out the indexs to help with updates latter\n",
    "    idx = df.index\n",
    "\n",
    "    ## create the embedings\n",
    "    name_vect = TfidfVectorizer(lowercase=False, analyzer='char_wb', ngram_range=(3,5)).fit_transform(df['name_clean'])\n",
    "    addrss_vect = TfidfVectorizer(lowercase=False, analyzer='char_wb', ngram_range=(3,5)).fit_transform(df['address_full']) \n",
    "\n",
    "    ## weight name higher then address and add \n",
    "    ## them to one matrix\n",
    "    features = hstack([\n",
    "            name_vect * .8,\n",
    "            addrss_vect * .2,\n",
    "        ])\n",
    "\n",
    "    ## clsuter the records\n",
    "    clusterer = hdbscan.HDBSCAN(\n",
    "            min_cluster_size = mcs,\n",
    "            min_samples = ms,\n",
    "            metric=\"cosine\",\n",
    "        )\n",
    "\n",
    "    ## pull out the labels\n",
    "    labels = clusterer.fit_predict(features)\n",
    "\n",
    "    ## test list is used to update the dataframe\n",
    "    test_list = []\n",
    "    for i in labels:\n",
    "        if i == -1:\n",
    "             test_list.append(np.nan)\n",
    "        else:\n",
    "            test_list.append(clusterer.cluster_persistence_[i])\n",
    "\n",
    "    \n",
    "    #update the data frame\n",
    "    df.loc[idx, \"cluster_id\"] = labels\n",
    "    df.loc[idx, \"cluster_persistence\"] = test_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2543d0-02d1-4be3-a9b6-cb59612d3ed6",
   "metadata": {},
   "source": [
    "## Set Up TF-IDF functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2578684f-4599-4dc7-bbae-9b9279f47ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_clusters(thrs_hold):\n",
    "    '''\n",
    "    Used to id a list of clusters \n",
    "    that may need to be compress into one\n",
    "    This is more important during the blocked \n",
    "    clustering. the idea is that some clsuters \n",
    "    that should have been put together did not end that\n",
    "    way. This takes in the summary records form the process\n",
    "    and compares the top names.\n",
    "    '''\n",
    "\n",
    "    input_data = (\n",
    "        thrs_hold['top_name'] +' '+\n",
    "        thrs_hold['top_address']\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    match_list=list()\n",
    "    \n",
    "    for i in range(len(input_data)):\n",
    "        clstr_tfidf = TfidfVectorizer()\n",
    "        clstr_matrix = clstr_tfidf.fit_transform(input_data.drop(i))\n",
    "        test_vect = clstr_tfidf.transform([str(input_data[i])])\n",
    "    \n",
    "        cosine_sim = linear_kernel(test_vect,clstr_matrix).flatten()\n",
    "        top_result_indx=cosine_sim.argsort()[:-10:-1][0]\n",
    "    \n",
    "    \n",
    "        if cosine_sim[top_result_indx] >= .9:\n",
    "            match_text = input_data[top_result_indx]\n",
    "            cosine_sim_value=cosine_sim[top_result_indx]\n",
    "            match_list.append((input_data[i],match_text,cosine_sim_value,top_result_indx))\n",
    "\n",
    "    return match_list\n",
    "\n",
    "def apply_clstrs(acptd_clrs:pd.DataFrame, fll_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    This takes a list of accepted clusters and uses it to \n",
    "    Apply labels to the dataset using TF-IDF.\n",
    "    This is used to test the process.\n",
    "    '''\n",
    "\n",
    "\n",
    "    ### make matching matrix\n",
    "    input_data = (\n",
    "        acptd_clrs['name_clean'] +' '+\n",
    "        acptd_clrs['address_full']\n",
    "    )\n",
    "\n",
    "    clstr_tfidf = TfidfVectorizer()\n",
    "    clstr_matrix = clstr_tfidf.fit_transform(input_data)\n",
    "\n",
    "\n",
    "    ### create test input - reuse the varable as input_data isn't needed anymore the index pull\n",
    "    ### will match back to acptd_clrs\n",
    "    input_data = (\n",
    "        fll_df['name_clean'] +' '+\n",
    "        fll_df['address_full']\n",
    "    )\n",
    "\n",
    "    \n",
    "    ### match to the data from the good clusters and apply it to the data set\n",
    "    for i in range(len(input_data)):\n",
    "        test_vect = clstr_tfidf.transform([str(input_data[i])])\n",
    "\n",
    "        cosine_sim = linear_kernel(test_vect,clstr_matrix).flatten()\n",
    "\n",
    "        top_result_indx=cosine_sim.argsort()[:-10:-1][0]\n",
    "\n",
    "        if top_result_indx >= .9:\n",
    "            fll_df.loc[i, \"match_name\"] = acptd_clrs['cluster_name'].at[top_result_indx]\n",
    "\n",
    "\n",
    "    return fll_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b1bb8-8ed1-46f5-b3c6-573b1e1d9cb3",
   "metadata": {},
   "source": [
    "## Set up Evaluations Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a79ade1-be4c-4441-b4cc-7aad3b5ead5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_meterics(sum_df:pd.DataFrame,val_df:pd.DataFrame, output_name:str):\n",
    "    '''\n",
    "    this was created to evualte the functions. this needs clean up in the future.\n",
    "    spits out all the stuff needed to evualte how well the clsutering did.\n",
    "    creates files in teh outputs folder.\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    copy_of_full_fr_tst = sum_df[['name_clean','address_full']].copy()\n",
    "    \n",
    "    ## Create summary df - got parts of this from ChatGtp\n",
    "    summary = (\n",
    "    sum_df[sum_df[\"cluster_id\"] != -1]\n",
    "    .groupby(\"cluster_id\")\n",
    "    .apply(lambda g: pd.Series({\n",
    "        \"cluster_size\": len(g),\n",
    "        \"top_name\": g[\"name_clean\"].value_counts().idxmax(),\n",
    "        \"top_address\": g[\"address_full\"].value_counts().idxmax(),\n",
    "        \"top_name_pct\": (\n",
    "            g[\"name_clean\"]\n",
    "            .value_counts(normalize=True)\n",
    "            .iloc[0]\n",
    "        ),\n",
    "        \"top_address_pct\": (\n",
    "            g[\"address_full\"]\n",
    "            .value_counts(normalize=True)\n",
    "            .iloc[0]\n",
    "        ),\n",
    "        \"cluster_persistence\":g['cluster_persistence'].max()\n",
    "    }))\n",
    "    .reset_index()\n",
    "    )\n",
    "\n",
    "    ## create meteric\n",
    "    total_recs = len(sum_df)\n",
    "    nmbr_of_clstrs = len(sum_df.groupby('cluster_id').size().rename('cluster_size'))\n",
    "    nmbr_of_clstrs_prs = len(summary[summary['cluster_persistence'] >= .9])\n",
    "    nmbr_tp_nm = len(summary[summary['top_name_pct'] >= .7])\n",
    "    nmbr_sz_20 = len(summary[summary['cluster_size'] >= 20])\n",
    "\n",
    "    print(f'Total number of input records: {total_recs}')\n",
    "    print(f'total number of clusters: {nmbr_of_clstrs}')\n",
    "    print(f'Total number of clusters with cluster_persistence at >= .9: {nmbr_of_clstrs_prs}')\n",
    "    print(f'Total number of Clusters with top_name_pct >- .7: {nmbr_tp_nm}')\n",
    "    print(f'Total number of Clsuers with size over 20: {nmbr_sz_20}')    \n",
    "\n",
    "    #output summary values\n",
    "    summary.sort_values(by=['cluster_size','cluster_persistence']).to_excel(f'outputs/{output_name}_summary.xlsx')\n",
    "\n",
    "    ## Thresholds index rest here is important\n",
    "    thrs_hold = summary[(summary['cluster_size'] >= 20) & (summary['cluster_persistence'] >= 1) &  (summary['top_name_pct'] >= .7)].reset_index()\n",
    "    cls_clstrs = close_clusters(thrs_hold)\n",
    "\n",
    "    ##create renaming dic to apply clusters to inputed data\n",
    "    top_nms_dict = dict(zip(thrs_hold['cluster_id'].to_list(),thrs_hold['top_name'].to_list()))\n",
    "    grps = thrs_hold['cluster_id'].to_list()\n",
    "    \n",
    "\n",
    "    ## Split cluster data for accepted clusters\n",
    "    cltrd_df = sum_df[sum_df['cluster_id'].isin(grps)].copy()\n",
    "    cltrd_df['cluster_name'] = cltrd_df['cluster_id'].map(top_nms_dict)\n",
    "\n",
    "    rmning_rcs = len(sum_df[~sum_df['cluster_id'].isin(grps)].copy())\n",
    "    clstrd_rcs = len(cltrd_df)\n",
    "\n",
    "    print(f'Remaining Records after accepted clusters: {rmning_rcs}')\n",
    "    print(f'Accepted Cluster Records:{clstrd_rcs}')\n",
    "\n",
    "    \n",
    "\n",
    "    ##see how good the clusters data is \n",
    "    clstrd_rcs = pd.merge(cltrd_df,val_df,  left_index=True, right_index=True)\n",
    "    ## making label name look like cleaned names.\n",
    "    clstrd_rcs['label_name'] = clstrd_rcs['label_name'].apply(normalize_name)\n",
    "    \n",
    "    clstrd_rcs['match_ind'] = clstrd_rcs.apply(lambda row: lev.ratio(row['label_name'],row['cluster_name']), axis=1)\n",
    "    full_mtch_val = len(clstrd_rcs[clstrd_rcs['match_ind'] == 1])\n",
    "\n",
    "    print(f'Number of 100% matchs in clstrs: {full_mtch_val}')\n",
    "\n",
    "    clstrd_rcs.to_excel(f'outputs/{output_name}_accepted_clusters.xlsx')\n",
    "\n",
    "    \n",
    "\n",
    "    ## use accepted clusters on test data and join to vaildate data to see how well it did\n",
    "    ## this dosn't have the looping in it but we are just proving the concept right now\n",
    "    fd = apply_clstrs(clstrd_rcs.reset_index(), copy_of_full_fr_tst)\n",
    "    fd = pd.merge(fd,val_df,  left_index=True, right_index=True)\n",
    "    fd['label_name'] = fd['label_name'].apply(normalize_name)\n",
    "    fd['match_pct'] = fd.apply(lambda row: lev.ratio(row['label_name'],row['match_name']), axis=1)\n",
    "    fd_full_mtch_val = len(fd[fd['match_pct'] == 1])\n",
    "\n",
    "    print(f'Number of 100% matchs in full data: {fd_full_mtch_val}')\n",
    "    fd.to_excel(f'outputs/{output_name}_full_data_match.xlsx')\n",
    "\n",
    "    print('\\n \\n \\n')\n",
    "    print(cls_clstrs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a87c8-bdd6-41f4-9c01-3cd0c60155f0",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13c3df22-c7a3-44e4-8fd4-8acd3916081e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label_address</th>\n",
       "      <th>label_city</th>\n",
       "      <th>label_postalzip</th>\n",
       "      <th>label_state</th>\n",
       "      <th>label_phone</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>state</th>\n",
       "      <th>phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12001</td>\n",
       "      <td>Vestibulum Accumsan Neque Consulting</td>\n",
       "      <td>6037 Nulla St.</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>56179</td>\n",
       "      <td>KS</td>\n",
       "      <td>3040776287</td>\n",
       "      <td>Vestibulum Accumsan Neque Consulting</td>\n",
       "      <td>6037 Nulla St.</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>56179</td>\n",
       "      <td>KS</td>\n",
       "      <td>3040776287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10297</td>\n",
       "      <td>Pede Limited</td>\n",
       "      <td>740-5881 Facilisis St.</td>\n",
       "      <td>Lewiston</td>\n",
       "      <td>12737</td>\n",
       "      <td>KS</td>\n",
       "      <td>3987433483</td>\n",
       "      <td>Psejmitc</td>\n",
       "      <td>07-58 8aFcilisist.</td>\n",
       "      <td>eaisfon</td>\n",
       "      <td>12773</td>\n",
       "      <td>SK</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7751</td>\n",
       "      <td>Pede Limited</td>\n",
       "      <td>740-5881 Facilisis St.</td>\n",
       "      <td>Lewiston</td>\n",
       "      <td>12737</td>\n",
       "      <td>KS</td>\n",
       "      <td>3987433483</td>\n",
       "      <td>Pred Lmietd</td>\n",
       "      <td>74-0518 FcilsixSt.</td>\n",
       "      <td>Lswisofj</td>\n",
       "      <td>173</td>\n",
       "      <td>KS</td>\n",
       "      <td>3874348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2593</td>\n",
       "      <td>Euismod Mauris Company</td>\n",
       "      <td>P.O. Box 564, 3029 Cum Avenue</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>11088</td>\n",
       "      <td>NE</td>\n",
       "      <td>5088427862</td>\n",
       "      <td>Euuaomd aMr iComoayn</td>\n",
       "      <td>P.OoBx 564, 3029 CuQ venue</td>\n",
       "      <td>NewU agdn</td>\n",
       "      <td>1108</td>\n",
       "      <td>E</td>\n",
       "      <td>5847862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5747</td>\n",
       "      <td>Euismod Mauris Company</td>\n",
       "      <td>P.O. Box 564, 3029 Cum Avenue</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>11088</td>\n",
       "      <td>NE</td>\n",
       "      <td>5088427862</td>\n",
       "      <td>Euwomd</td>\n",
       "      <td>PO. xB 56 0 Cmj Avneye</td>\n",
       "      <td>Hwe Hvnw</td>\n",
       "      <td>1188</td>\n",
       "      <td>NE</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            label_name  \\\n",
       "0       12001  Vestibulum Accumsan Neque Consulting   \n",
       "1       10297                          Pede Limited   \n",
       "2        7751                          Pede Limited   \n",
       "3        2593                Euismod Mauris Company   \n",
       "4        5747                Euismod Mauris Company   \n",
       "\n",
       "                   label_address label_city  label_postalzip label_state  \\\n",
       "0                 6037 Nulla St.    Olympia            56179          KS   \n",
       "1         740-5881 Facilisis St.   Lewiston            12737          KS   \n",
       "2         740-5881 Facilisis St.   Lewiston            12737          KS   \n",
       "3  P.O. Box 564, 3029 Cum Avenue  New Haven            11088          NE   \n",
       "4  P.O. Box 564, 3029 Cum Avenue  New Haven            11088          NE   \n",
       "\n",
       "   label_phone                                  name  \\\n",
       "0   3040776287  Vestibulum Accumsan Neque Consulting   \n",
       "1   3987433483                              Psejmitc   \n",
       "2   3987433483                           Pred Lmietd   \n",
       "3   5088427862                  Euuaomd aMr iComoayn   \n",
       "4   5088427862                                Euwomd   \n",
       "\n",
       "                      address       city    zip state       phone  \n",
       "0              6037 Nulla St.    Olympia  56179    KS  3040776287  \n",
       "1          07-58 8aFcilisist.    eaisfon  12773    SK         938  \n",
       "2          74-0518 FcilsixSt.   Lswisofj    173    KS     3874348  \n",
       "3  P.OoBx 564, 3029 CuQ venue  NewU agdn   1108     E     5847862  \n",
       "4      PO. xB 56 0 Cmj Avneye   Hwe Hvnw   1188    NE          50  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\dkh18\\\\python_projects\\\\DSC680\\\\Project 1\\\\Company_Name_Clusterer\\\\data\\\\scarmble_data_small.csv')\n",
    "\n",
    "df = df.rename(columns = {'test_name':'name',\n",
    "                     'test_address':'address',\n",
    "                     'test_city':'city',\n",
    "                     'test_postalzip':'zip',\n",
    "                     'test_state':'state',\n",
    "                     'test_phone':'phone'})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c3bb13-91d9-4ae0-b65b-1f9b96ee6e6c",
   "metadata": {},
   "source": [
    "## Clean and normalize the name filed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21c2ede-3967-48ca-b5a4-2c4ad42243fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label_address</th>\n",
       "      <th>label_city</th>\n",
       "      <th>label_postalzip</th>\n",
       "      <th>label_state</th>\n",
       "      <th>label_phone</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>state</th>\n",
       "      <th>phone</th>\n",
       "      <th>name_clean</th>\n",
       "      <th>name_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12001</td>\n",
       "      <td>Vestibulum Accumsan Neque Consulting</td>\n",
       "      <td>6037 Nulla St.</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>56179</td>\n",
       "      <td>KS</td>\n",
       "      <td>3040776287</td>\n",
       "      <td>Vestibulum Accumsan Neque Consulting</td>\n",
       "      <td>6037 Nulla St.</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>56179</td>\n",
       "      <td>KS</td>\n",
       "      <td>3040776287</td>\n",
       "      <td>VESTIBULUM ACCUMSAN NEQUE CONSULTING</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10297</td>\n",
       "      <td>Pede Limited</td>\n",
       "      <td>740-5881 Facilisis St.</td>\n",
       "      <td>Lewiston</td>\n",
       "      <td>12737</td>\n",
       "      <td>KS</td>\n",
       "      <td>3987433483</td>\n",
       "      <td>Psejmitc</td>\n",
       "      <td>07-58 8aFcilisist.</td>\n",
       "      <td>eaisfon</td>\n",
       "      <td>12773</td>\n",
       "      <td>SK</td>\n",
       "      <td>938</td>\n",
       "      <td>PSEJMITC</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7751</td>\n",
       "      <td>Pede Limited</td>\n",
       "      <td>740-5881 Facilisis St.</td>\n",
       "      <td>Lewiston</td>\n",
       "      <td>12737</td>\n",
       "      <td>KS</td>\n",
       "      <td>3987433483</td>\n",
       "      <td>Pred Lmietd</td>\n",
       "      <td>74-0518 FcilsixSt.</td>\n",
       "      <td>Lswisofj</td>\n",
       "      <td>173</td>\n",
       "      <td>KS</td>\n",
       "      <td>3874348</td>\n",
       "      <td>PRED LMIETD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2593</td>\n",
       "      <td>Euismod Mauris Company</td>\n",
       "      <td>P.O. Box 564, 3029 Cum Avenue</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>11088</td>\n",
       "      <td>NE</td>\n",
       "      <td>5088427862</td>\n",
       "      <td>Euuaomd aMr iComoayn</td>\n",
       "      <td>P.OoBx 564, 3029 CuQ venue</td>\n",
       "      <td>NewU agdn</td>\n",
       "      <td>1108</td>\n",
       "      <td>E</td>\n",
       "      <td>5847862</td>\n",
       "      <td>EUUAOMD AMR ICOMOAYN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5747</td>\n",
       "      <td>Euismod Mauris Company</td>\n",
       "      <td>P.O. Box 564, 3029 Cum Avenue</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>11088</td>\n",
       "      <td>NE</td>\n",
       "      <td>5088427862</td>\n",
       "      <td>Euwomd</td>\n",
       "      <td>PO. xB 56 0 Cmj Avneye</td>\n",
       "      <td>Hwe Hvnw</td>\n",
       "      <td>1188</td>\n",
       "      <td>NE</td>\n",
       "      <td>50</td>\n",
       "      <td>EUWOMD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            label_name  \\\n",
       "0       12001  Vestibulum Accumsan Neque Consulting   \n",
       "1       10297                          Pede Limited   \n",
       "2        7751                          Pede Limited   \n",
       "3        2593                Euismod Mauris Company   \n",
       "4        5747                Euismod Mauris Company   \n",
       "\n",
       "                   label_address label_city  label_postalzip label_state  \\\n",
       "0                 6037 Nulla St.    Olympia            56179          KS   \n",
       "1         740-5881 Facilisis St.   Lewiston            12737          KS   \n",
       "2         740-5881 Facilisis St.   Lewiston            12737          KS   \n",
       "3  P.O. Box 564, 3029 Cum Avenue  New Haven            11088          NE   \n",
       "4  P.O. Box 564, 3029 Cum Avenue  New Haven            11088          NE   \n",
       "\n",
       "   label_phone                                  name  \\\n",
       "0   3040776287  Vestibulum Accumsan Neque Consulting   \n",
       "1   3987433483                              Psejmitc   \n",
       "2   3987433483                           Pred Lmietd   \n",
       "3   5088427862                  Euuaomd aMr iComoayn   \n",
       "4   5088427862                                Euwomd   \n",
       "\n",
       "                      address       city    zip state       phone  \\\n",
       "0              6037 Nulla St.    Olympia  56179    KS  3040776287   \n",
       "1          07-58 8aFcilisist.    eaisfon  12773    SK         938   \n",
       "2          74-0518 FcilsixSt.   Lswisofj    173    KS     3874348   \n",
       "3  P.OoBx 564, 3029 CuQ venue  NewU agdn   1108     E     5847862   \n",
       "4      PO. xB 56 0 Cmj Avneye   Hwe Hvnw   1188    NE          50   \n",
       "\n",
       "                             name_clean  name_ind  \n",
       "0  VESTIBULUM ACCUMSAN NEQUE CONSULTING      True  \n",
       "1                              PSEJMITC      True  \n",
       "2                           PRED LMIETD      True  \n",
       "3                  EUUAOMD AMR ICOMOAYN      True  \n",
       "4                                EUWOMD      True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name_clean'] = df['name'].apply(normalize_name)\n",
    "# df['name_clean'] = df['name_clean'].apply(lambda x: replace_values(x,LEGAL_SUFFIXES))\n",
    "df['name_clean'] = df['name_clean'].apply(remove_extra_spaces)\n",
    "df['name_ind'] = df['name_clean'].str.len() >=1\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b3c73-e597-4125-96c8-25cbd4118e8a",
   "metadata": {},
   "source": [
    "## Clean and normalize the address fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b53890cb-7d14-4982-b0d5-e4670e68d87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label_address</th>\n",
       "      <th>label_city</th>\n",
       "      <th>label_postalzip</th>\n",
       "      <th>label_state</th>\n",
       "      <th>label_phone</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>zip</th>\n",
       "      <th>state</th>\n",
       "      <th>phone</th>\n",
       "      <th>name_clean</th>\n",
       "      <th>name_ind</th>\n",
       "      <th>vaild_state_ind</th>\n",
       "      <th>zip_ind</th>\n",
       "      <th>address_full</th>\n",
       "      <th>address_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12001</td>\n",
       "      <td>Vestibulum Accumsan Neque Consulting</td>\n",
       "      <td>6037 Nulla St.</td>\n",
       "      <td>Olympia</td>\n",
       "      <td>56179</td>\n",
       "      <td>KS</td>\n",
       "      <td>3040776287</td>\n",
       "      <td>Vestibulum Accumsan Neque Consulting</td>\n",
       "      <td>6037 NULLA ST</td>\n",
       "      <td>OLYMPIA</td>\n",
       "      <td>56179</td>\n",
       "      <td>KS</td>\n",
       "      <td>3040776287</td>\n",
       "      <td>VESTIBULUM ACCUMSAN NEQUE CONSULTING</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6037 NULLA ST OLYMPIA KS 56179</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10297</td>\n",
       "      <td>Pede Limited</td>\n",
       "      <td>740-5881 Facilisis St.</td>\n",
       "      <td>Lewiston</td>\n",
       "      <td>12737</td>\n",
       "      <td>KS</td>\n",
       "      <td>3987433483</td>\n",
       "      <td>Psejmitc</td>\n",
       "      <td>07 58 8AFCILISIST</td>\n",
       "      <td>EAISFON</td>\n",
       "      <td>12773</td>\n",
       "      <td>SK</td>\n",
       "      <td>938</td>\n",
       "      <td>PSEJMITC</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>07 58 8AFCILISIST EAISFON SK 12773</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7751</td>\n",
       "      <td>Pede Limited</td>\n",
       "      <td>740-5881 Facilisis St.</td>\n",
       "      <td>Lewiston</td>\n",
       "      <td>12737</td>\n",
       "      <td>KS</td>\n",
       "      <td>3987433483</td>\n",
       "      <td>Pred Lmietd</td>\n",
       "      <td>74 0518 FCILSIXST</td>\n",
       "      <td>LSWISOFJ</td>\n",
       "      <td>173</td>\n",
       "      <td>KS</td>\n",
       "      <td>3874348</td>\n",
       "      <td>PRED LMIETD</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>74 0518 FCILSIXST LSWISOFJ KS 173</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2593</td>\n",
       "      <td>Euismod Mauris Company</td>\n",
       "      <td>P.O. Box 564, 3029 Cum Avenue</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>11088</td>\n",
       "      <td>NE</td>\n",
       "      <td>5088427862</td>\n",
       "      <td>Euuaomd aMr iComoayn</td>\n",
       "      <td>P OOBX 564 3029 CUQ VENUE</td>\n",
       "      <td>NEWU AGDN</td>\n",
       "      <td>1108</td>\n",
       "      <td>E</td>\n",
       "      <td>5847862</td>\n",
       "      <td>EUUAOMD AMR ICOMOAYN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>P OOBX 564 3029 CUQ VENUE NEWU AGDN E 1108</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5747</td>\n",
       "      <td>Euismod Mauris Company</td>\n",
       "      <td>P.O. Box 564, 3029 Cum Avenue</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>11088</td>\n",
       "      <td>NE</td>\n",
       "      <td>5088427862</td>\n",
       "      <td>Euwomd</td>\n",
       "      <td>PO XB 56 0 CMJ AVNEYE</td>\n",
       "      <td>HWE HVNW</td>\n",
       "      <td>1188</td>\n",
       "      <td>NE</td>\n",
       "      <td>50</td>\n",
       "      <td>EUWOMD</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PO XB 56 0 CMJ AVNEYE HWE HVNW NE 1188</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            label_name  \\\n",
       "0       12001  Vestibulum Accumsan Neque Consulting   \n",
       "1       10297                          Pede Limited   \n",
       "2        7751                          Pede Limited   \n",
       "3        2593                Euismod Mauris Company   \n",
       "4        5747                Euismod Mauris Company   \n",
       "\n",
       "                   label_address label_city  label_postalzip label_state  \\\n",
       "0                 6037 Nulla St.    Olympia            56179          KS   \n",
       "1         740-5881 Facilisis St.   Lewiston            12737          KS   \n",
       "2         740-5881 Facilisis St.   Lewiston            12737          KS   \n",
       "3  P.O. Box 564, 3029 Cum Avenue  New Haven            11088          NE   \n",
       "4  P.O. Box 564, 3029 Cum Avenue  New Haven            11088          NE   \n",
       "\n",
       "   label_phone                                  name  \\\n",
       "0   3040776287  Vestibulum Accumsan Neque Consulting   \n",
       "1   3987433483                              Psejmitc   \n",
       "2   3987433483                           Pred Lmietd   \n",
       "3   5088427862                  Euuaomd aMr iComoayn   \n",
       "4   5088427862                                Euwomd   \n",
       "\n",
       "                     address       city    zip state       phone  \\\n",
       "0              6037 NULLA ST    OLYMPIA  56179    KS  3040776287   \n",
       "1          07 58 8AFCILISIST    EAISFON  12773    SK         938   \n",
       "2          74 0518 FCILSIXST   LSWISOFJ    173    KS     3874348   \n",
       "3  P OOBX 564 3029 CUQ VENUE  NEWU AGDN   1108     E     5847862   \n",
       "4      PO XB 56 0 CMJ AVNEYE   HWE HVNW   1188    NE          50   \n",
       "\n",
       "                             name_clean  name_ind  vaild_state_ind  zip_ind  \\\n",
       "0  VESTIBULUM ACCUMSAN NEQUE CONSULTING      True             True     True   \n",
       "1                              PSEJMITC      True            False     True   \n",
       "2                           PRED LMIETD      True             True    False   \n",
       "3                  EUUAOMD AMR ICOMOAYN      True            False    False   \n",
       "4                                EUWOMD      True             True    False   \n",
       "\n",
       "                                 address_full  address_ind  \n",
       "0              6037 NULLA ST OLYMPIA KS 56179         True  \n",
       "1          07 58 8AFCILISIST EAISFON SK 12773         True  \n",
       "2           74 0518 FCILSIXST LSWISOFJ KS 173         True  \n",
       "3  P OOBX 564 3029 CUQ VENUE NEWU AGDN E 1108         True  \n",
       "4      PO XB 56 0 CMJ AVNEYE HWE HVNW NE 1188         True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['address'] = df['address'].apply(normalize_text)\n",
    "df['address'] = df['address'].apply(lambda x: replace_values(x,STREET_MAP))\n",
    "df['address'] = df['address'].apply(lambda x: replace_values(x,DIRECTION_MAP))\n",
    "df['address'] = df['address'].apply(lambda x: replace_values(x,UNIT_MAP))\n",
    "df['address'] = df['address'].apply(remove_extra_spaces)\n",
    "\n",
    "\n",
    "df['city'] = df['city'].apply(normalize_text)\n",
    "df['city'] = df['city'].apply(remove_extra_spaces)\n",
    "\n",
    "df['state'] = df['state'].apply(normalize_text)\n",
    "df['state'] = df['state'].apply(remove_extra_spaces)\n",
    "df['vaild_state_ind'] = df['state'].apply(lambda x : check_if_value_exists(x,US_STATES))\n",
    "\n",
    "\n",
    "df['zip'] = df['zip'].apply(lambda x: str(x)[0:5])\n",
    "df['zip_ind'] = df['zip'].astype(str).str.len() == 5\n",
    "\n",
    "\n",
    "df['address_full'] = (\n",
    "    df['address'] + ' ' +\n",
    "    df['city'] + ' ' +\n",
    "    df['state'] + ' ' +\n",
    "    df['zip']\n",
    ")\n",
    "\n",
    "df['address_ind'] = df['address_full'].str.len() > 0\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee72616-4000-4421-b812-635dbbb9a9f6",
   "metadata": {},
   "source": [
    "## Review the state of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "969e87b0-dd7d-45c1-9c62-0958d9c939d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad names: 3\n",
      "bad states: 5595\n",
      "bad zips: 6691\n",
      "bad addrss: 0\n",
      "record count: 15200\n"
     ]
    }
   ],
   "source": [
    "print(f'bad names: {sum(df['name_ind']==False)}')\n",
    "print(f'bad states: {sum(df['vaild_state_ind']==False)}')\n",
    "print(f'bad zips: {sum(df['zip_ind']==False)}')\n",
    "print(f'bad addrss: {sum(df['address_ind']==False)}')\n",
    "print(f'record count: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d686f37-e909-4098-a0ea-36173b2d25e8",
   "metadata": {},
   "source": [
    "# Prep Data for Clustering\n",
    "\n",
    "split the test from teh vaildate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a611e44-38a2-4cca-bb6a-dcaab6070813",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='name_clean')\n",
    "\n",
    "vaildate_df = df['label_name'].copy()\n",
    "test_df = df[['name_clean','address_full','phone']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a05b2a-e1a3-4594-9e1a-45bd02ec9dec",
   "metadata": {},
   "source": [
    "# Run Cluster Tests \n",
    "\n",
    "Here we are just trying out different cluster parameters to see how well the process works. This sets the min cluster size and sample size.\n",
    "we can also prove out how well the process is working here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460c7082-9a24-4ec0-8a12-1e85b2a1ce9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkh18\\AppData\\Local\\Temp\\ipykernel_49424\\4285876529.py:16: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input records: 15200\n",
      "total number of clusters: 1548\n",
      "Total number of clusters with cluster_persistence at >= .9: 1547\n",
      "Total number of Clusters with top_name_pct >- .7: 56\n",
      "Total number of Clsuers with size over 20: 19\n",
      "Remaining Records after accepted clusters: 9094\n",
      "Accepted Cluster Records:6106\n",
      "Number of 100% matchs in clstrs: 6105\n",
      "Number of 100% matchs in full data: 10704\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "small_cluster(test_df, 2, 1)\n",
    "run_meterics(test_df, vaildate_df, 'test_2_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a835a021-395d-40c2-8794-465aa3c78b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkh18\\AppData\\Local\\Temp\\ipykernel_49424\\4285876529.py:16: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input records: 15200\n",
      "total number of clusters: 253\n",
      "Total number of clusters with cluster_persistence at >= .9: 252\n",
      "Total number of Clusters with top_name_pct >- .7: 32\n",
      "Total number of Clsuers with size over 20: 22\n",
      "Remaining Records after accepted clusters: 9064\n",
      "Accepted Cluster Records:6136\n",
      "Number of 100% matchs in clstrs: 6135\n",
      "Number of 100% matchs in full data: 10462\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "small_cluster(test_df, 5, 1)\n",
    "run_meterics(test_df, vaildate_df, 'test_5_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e818fc58-b38b-4640-83a7-f27b598c17d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dkh18\\AppData\\Local\\Temp\\ipykernel_49424\\4285876529.py:16: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input records: 15200\n",
      "total number of clusters: 468\n",
      "Total number of clusters with cluster_persistence at >= .9: 467\n",
      "Total number of Clusters with top_name_pct >- .7: 37\n",
      "Total number of Clsuers with size over 20: 20\n",
      "Remaining Records after accepted clusters: 9072\n",
      "Accepted Cluster Records:6128\n",
      "Number of 100% matchs in clstrs: 6128\n",
      "Number of 100% matchs in full data: 10585\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "small_cluster(test_df, 2, 3)\n",
    "run_meterics(test_df, vaildate_df, 'test_2_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a96ad2-fb0e-40d0-8800-f4837ed229e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
